{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai langchain chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_excel(\"topical_chat.xlsx\")\n",
    "main_df = main_df.dropna()\n",
    "main_df = main_df[main_df['message'].notna() & (main_df['message'] != '')]\n",
    "main_df = main_df.reset_index(drop=True)\n",
    "\n",
    "first_100_conversations = main_df[main_df[\"conversation_id\"] <= 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Conversation ids: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100]\n"
     ]
    }
   ],
   "source": [
    "#group messages with same conversation id\n",
    "unique_conversations_ids = first_100_conversations['conversation_id'].unique()\n",
    "print(\"Unique Conversation ids:\", unique_conversations_ids)\n",
    "\n",
    "\n",
    "texts = []\n",
    "\n",
    "for conversation_id in unique_conversations_ids:\n",
    "    x = first_100_conversations[first_100_conversations[\"conversation_id\"] == conversation_id]\n",
    "    texts.append({\"id\" : conversation_id , \"text\" : \"\\n \".join(x[\"message\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chat_models import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "llm = ChatOpenAI() # add openai credentials\n",
    "\n",
    "class AnswerModel(BaseModel):\n",
    "    summary: str = Field(description=\"summary of the given conversation\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=AnswerModel)\n",
    "\n",
    "template = \"\"\"Summarize the given chat context in short and generate 2-3 lines of summary. context : {context},\\n format instructions : {format_instructions}\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize(conversation_id):\n",
    "\n",
    "    context = texts[conversation_id][\"text\"]\n",
    "\n",
    "    input = prompt.format_prompt(context=context)\n",
    "    o = llm.predict(input.to_string())\n",
    "    retry_parser = RetryWithErrorOutputParser.from_llm(parser=parser, llm=llm)\n",
    "    model = retry_parser.parse_with_prompt(o, input)\n",
    "    return model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you like dance?\n",
      " Yes  I do. Did you know Bruce Lee was a cha cha dancer?\n",
      " Yes he even won a hardcore cha cha championship in 1958\n",
      " Yeah. Did you know Tupac was a ballet dancer?\n",
      " Yes and he even was in the production of the nutcracker\n",
      " Yeah. Ballet dancer go through 4 pairs of shoes a week\n",
      " Yes that is a lot of shoes and also a lot of money\n",
      " Yeah true. Did you know babies are really good at dancing?\n",
      " Yes and they smile more when they hit the beat\n",
      " Yeah they are much smarter than we give them credit for\n",
      " True Did you know Jackson had a patent on a dancing device?\n",
      " Yes it helped him smooth out his dance moves\n",
      " Nice. Do you like Shakespeare?\n",
      " Yes I do. Do you know that he popularized many phrases\n",
      "  Yes like good riddance, in my heart of hearts and such\n",
      "  Yes and then he also invented names like Jessica, Olivia and Miranda\n",
      " Yes. And for his works you have to use old english for it to make sense\n",
      " Yes otherwise the rhymes and puns do not seem to work out\n",
      " Yes. He lived at the same time as Pocahontas too\n",
      " I wonder if they met how that would go from there\n",
      " Yeah interesting point. Nice chat\n"
     ]
    }
   ],
   "source": [
    "print(texts[1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation revolves around various interesting facts about dance and Shakespeare. The participants discuss Bruce Lee's cha cha dancing, Tupac's ballet dancing, Michael Jackson's patented dancing device, and the natural dancing ability of babies. They also discuss Shakespeare's contribution to English language, his invention of names, and the necessity of using Old English to understand his works.\n"
     ]
    }
   ],
   "source": [
    "print(summarize(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing summary of 1st conversation to task_2_summaries folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:28<00:00,  5.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def write_to_files(prefix=\"summary_conversation\"):\n",
    "\n",
    "    for id in tqdm(range(len(unique_conversations_ids))):\n",
    "        summary = summarize(id)\n",
    "        filename = os.path.join(\"task_2_summaries\",f\"{prefix}_{id+1}.txt\")\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(summary)\n",
    "\n",
    "write_to_files()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
